[pytest]
# pytest configuration for comprehensive Clean Architecture testing

# Test discovery
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test markers - Clean Architecture Layer Support
markers =
    # Clean Architecture Layer Markers
    domain: marks tests as domain layer tests (entities, value objects, business logic)
    application: marks tests as application layer tests (use cases, DTOs, interfaces)
    infrastructure: marks tests as infrastructure layer tests (repositories, adapters, external services)
    integration: marks tests as integration tests (cross-layer workflows)
    e2e: marks tests as end-to-end tests (complete system workflows)
    
    # Test Type Markers
    unit: marks tests as unit tests
    async_test: marks tests requiring async execution
    database: marks tests requiring database operations
    mcp_protocol: marks tests for MCP protocol compliance
    
    # Performance and Quality Markers
    performance: marks tests as performance benchmarks
    slow: marks tests as slow (deselect with '-m "not slow"')
    baseline: marks tests that establish performance baselines
    coverage_critical: marks tests critical for coverage requirements
    
    # Legacy and Maintenance Markers
    maintenance: marks tests specific to maintenance features
    streaming: marks tests specific to streaming features
    
    # Security Test Markers
    security: marks tests as security tests
    authentication: marks tests as authentication security tests
    authorization: marks tests as authorization security tests
    xss: marks tests as XSS prevention tests
    path_traversal: marks tests as path traversal security tests
    critical: marks tests as critical security tests
    attack_simulation: marks tests as attack simulation tests
    information_disclosure: marks tests as information disclosure prevention tests
    input_validation: marks tests as input validation security tests
    
    # Validation and Compliance Markers
    architectural_validation: marks tests that validate architectural compliance
    clean_architecture: marks tests ensuring Clean Architecture principles
    boundary_test: marks tests validating layer boundaries

# Test output
addopts = 
    --strict-markers
    --verbose
    --tb=short
    --color=yes
    --durations=10
    --showlocals
    --maxfail=5

# Asyncio configuration
asyncio_mode = auto

# Coverage options
[coverage:run]
source = vespera_scriptorium
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*
    */venv_test/*
    */archives/*
    */experimental/*
    */legacy-archive/*
    */backups/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abc.abstractmethod
    @abstractmethod
precision = 2
show_missing = true
fail_under = 95

[coverage:html]
directory = tests/coverage_html

[coverage:xml]
output = tests/coverage.xml

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Timeout for long-running tests
timeout = 300

# Test collection configuration
testpaths = tests
norecursedirs = 
    .git
    .pytest_cache
    *.egg
    venv*
    archives
    experimental
    legacy-archive
    backups

# Custom command line options
addopts = 
    --strict-config
    --strict-markers
    --verbose
    --tb=short
    --color=yes
    --durations=10
    --showlocals
    --maxfail=5

# Performance testing options
performance_baseline_file = tests/performance/baselines.json

# Parallel execution (if needed)
# -n auto