[pytest]
# pytest configuration for maintenance and streaming tests

# Test discovery
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test markers
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    performance: marks tests as performance benchmarks
    maintenance: marks tests specific to maintenance features
    streaming: marks tests specific to streaming features
    security: marks tests as security tests
    authentication: marks tests as authentication security tests
    authorization: marks tests as authorization security tests
    xss: marks tests as XSS prevention tests
    path_traversal: marks tests as path traversal security tests
    critical: marks tests as critical security tests
    attack_simulation: marks tests as attack simulation tests
    information_disclosure: marks tests as information disclosure prevention tests
    input_validation: marks tests as input validation security tests

# Test output
addopts = 
    --strict-markers
    --verbose
    --tb=short
    --color=yes

# Asyncio configuration
asyncio_mode = auto

# Coverage options
[coverage:run]
source = mcp_task_orchestrator
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */venv/*
    */venv_test/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Timeout for long-running tests
timeout = 300

# Parallel execution (if needed)
# -n auto