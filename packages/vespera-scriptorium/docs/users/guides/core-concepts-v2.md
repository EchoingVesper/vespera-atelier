# Core Concepts

Understanding these core concepts will help you get the most out of the MCP Task Orchestrator.

## The Documentation Automation Philosophy

The Task Orchestrator embodies a fundamental insight: **documentation shouldn't be something you do after the work - it should BE the work itself**. Instead of creating code and then trying to remember why you made certain decisions, the orchestrator captures every decision, trade-off, and implementation detail as it happens.

This means:

- Every task generates persistent artifacts
- All decisions are documented with context
- Future work builds on past understanding
- Nothing is ever lost or forgotten

## Tasks: The Foundation

A **task** is any piece of work you want to accomplish. Tasks in the orchestrator are:

- **Hierarchical**: Complex tasks break down into subtasks
- **Documented**: Every task generates artifacts
- **Persistent**: All tasks are saved in the database
- **Searchable**: Find any past task or decision

### Task Lifecycle

```
1. Planning     â†’ Break down the work
2. Assignment   â†’ Match specialists to subtasks  
3. Execution    â†’ Specialists do their work
4. Artifact Gen â†’ Save outputs and decisions
5. Synthesis    â†’ Combine into final result
```

### Example Task Hierarchy

```
"Build a CLI tool for file organization"
â”œâ”€â”€ Architecture Design
â”‚   â”œâ”€â”€ Define command structure
â”‚   â”œâ”€â”€ Plan file operations
â”‚   â””â”€â”€ Design configuration format
â”œâ”€â”€ Implementation
â”‚   â”œâ”€â”€ Core file operations
â”‚   â”œâ”€â”€ CLI argument parsing
â”‚   â”œâ”€â”€ Configuration handling
â”‚   â””â”€â”€ Error handling
â”œâ”€â”€ Testing
â”‚   â”œâ”€â”€ Unit tests
â”‚   â”œâ”€â”€ Integration tests
â”‚   â””â”€â”€ Edge case validation
â””â”€â”€ Documentation
    â”œâ”€â”€ Usage guide
    â”œâ”€â”€ API reference
    â””â”€â”€ Examples
```

## Specialists: Focused Expertise

Specialists are AI roles optimized for specific types of work. Each specialist:

- Has a defined area of expertise
- Follows best practices for their domain
- Generates specific types of artifacts
- Maintains consistency across tasks

### Built-in Specialists

#### ğŸ—ï¸ Architect
- **Focus**: System design and technology decisions
- **Outputs**: Architecture diagrams, design docs, technology evaluations
- **Artifacts**: `design/`, `decisions/`, `architecture.md`
- **Documentation**: Always explains *why* certain technologies or patterns were chosen

#### ğŸ’» Implementer
- **Focus**: Writing clean, maintainable code
- **Outputs**: Source code, configuration files, scripts
- **Artifacts**: `src/`, `config/`, implementation notes
- **Documentation**: Creates inline comments and implementation notes

#### ğŸ§ª Tester
- **Focus**: Comprehensive testing strategies
- **Outputs**: Test suites, test plans, coverage reports
- **Artifacts**: `tests/`, `test-plan.md`, coverage data
- **Documentation**: Documents test scenarios and edge cases

#### ğŸ” Reviewer
- **Focus**: Code quality, security, best practices
- **Outputs**: Review comments, improvement suggestions, security notes
- **Artifacts**: `reviews/`, security reports, refactoring suggestions
- **Documentation**: Captures quality concerns and improvement opportunities

#### ğŸ“ Documenter
- **Focus**: Clear, comprehensive documentation
- **Outputs**: User guides, API docs, tutorials
- **Artifacts**: `docs/`, README files, examples
- **Documentation**: Creates user-facing documentation from technical artifacts

#### ğŸ”§ Debugger
- **Focus**: Finding and fixing issues
- **Outputs**: Bug analyses, fixes, root cause documentation
- **Artifacts**: `fixes/`, debugging notes, solution explanations
- **Documentation**: Documents debugging process and solutions

#### ğŸš€ Optimizer
- **Focus**: Performance and efficiency
- **Outputs**: Performance analyses, optimized code, benchmarks
- **Artifacts**: `benchmarks/`, optimization reports
- **Documentation**: Documents performance improvements and trade-offs

## Artifacts: Persistent Knowledge

Artifacts are the permanent outputs of task execution. They serve as:

- **Documentation**: Capturing what was built
- **Context**: Explaining why decisions were made
- **Reference**: Informing future work
- **History**: Tracking project evolution

### Artifact Types

#### Code Artifacts
```python
# Generated by Implementer specialist
# Location: .task_orchestrator/artifacts/src/auth.py

"""Authentication module with JWT support.

Decision: Chose JWT over sessions for stateless scalability.
See: .task_orchestrator/decisions/auth-strategy.md
"""

import jwt
from datetime import datetime, timedelta

class Authenticator:
    """Handle user authentication with JWT tokens."""
    # ... implementation ...
```

#### Decision Artifacts
```markdown
# Authentication Strategy Decision
Date: 2024-01-15
Specialist: Architect
Task: Design authentication system

## Decision: JWT over Session-based Auth

### Reasoning:
1. **Stateless**: No server-side session storage needed
2. **Scalable**: Works across multiple servers
3. **Mobile-friendly**: Better for API-first design

### Trade-offs:
- Cannot revoke tokens (must wait for expiry)
- Slightly larger request size
- Need secure secret management

### Mitigation:
- Short token lifetime (15 minutes)
- Refresh token pattern
- HSM for production secrets
```

#### Test Artifacts
```python
# Generated by Tester specialist
# Location: .task_orchestrator/artifacts/tests/test_auth.py

import pytest
from auth import Authenticator

class TestAuthentication:
    """Test authentication flows and edge cases.
    
    Test scenarios derived from security requirements:
    - Token expiration
    - Invalid signatures  
    - Replay attacks
    - Concurrent sessions
    """
    # ... test implementation ...
```

### Artifact Organization

```
.task_orchestrator/
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ task_12345/
â”‚   â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ docs/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.md
â”‚   â”‚   â”‚   â””â”€â”€ guide.md
â”‚   â”‚   â”œâ”€â”€ decisions/
â”‚   â”‚   â”‚   â”œâ”€â”€ architecture.md
â”‚   â”‚   â”‚   â””â”€â”€ trade-offs.md
â”‚   â”‚   â””â”€â”€ reviews/
â”‚   â”‚       â””â”€â”€ security-review.md
â”‚   â””â”€â”€ task_12346/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ sessions/
â”‚   â””â”€â”€ current_session.json
â””â”€â”€ tasks.db
```

## Sessions: Work Context

A session represents a continuous period of work. Sessions:

- Track related tasks
- Maintain working context
- Enable task continuity
- Support interrupted work

### Session Initialization

```python
# Starting a new session
"Initialize task orchestrator session for building a web scraper"

# Creates:
# - Working directory detection
# - Session ID and metadata
# - Initial context capture
# - Database preparation
```

### Session Context

Sessions maintain context including:

- Current working directory
- Active tasks and subtasks
- Specialist assignments
- Configuration preferences
- Environmental constraints

## Workspace Awareness

The orchestrator automatically detects your project structure:

### Project Detection

Looks for these markers (in order):
1. `.git/` - Git repository root
2. `package.json` - Node.js project
3. `pyproject.toml` - Python project
4. `Cargo.toml` - Rust project
5. Current directory (fallback)

### Artifact Placement

```
detected-project-root/
â”œâ”€â”€ .task_orchestrator/    # Orchestrator data
â”œâ”€â”€ src/                   # Your source code
â”œâ”€â”€ tests/                 # Your tests
â””â”€â”€ docs/                  # Your documentation
```

## The Power of Memory: Query System

Unlike traditional AI conversations that lose context, the orchestrator remembers everything:

### Query Examples

```python
# Find all security-related tasks
"Show all tasks involving security considerations"

# Understand a decision
"Why did we choose PostgreSQL for this project?"

# Review test coverage
"What test scenarios have we covered for authentication?"

# Find optimization opportunities  
"Show all tasks marked for performance improvement"

# Understand evolution
"How has our API design evolved over time?"
```

### Query Results

Queries return:
- Task metadata (date, specialist, status)
- Generated artifacts
- Decision documentation
- Related tasks
- Historical context

## Task Relationships

Tasks can be related in several ways:

### Dependencies
```
Task A: "Design API"
    â†“ blocks
Task B: "Implement API"
    â†“ blocks  
Task C: "Write API tests"
```

### Hierarchies
```
Parent: "Build e-commerce site"
â”œâ”€â”€ Child: "User authentication"
â”œâ”€â”€ Child: "Product catalog"
â””â”€â”€ Child: "Shopping cart"
```

### References
```
Task 123: "Implement caching"
    â†’ references
Task 456: "Initial performance analysis"
```

## Documentation as a Side Effect

The key insight is that documentation becomes a natural byproduct of organized work rather than a separate burden:

### Traditional Approach
```
1. Write code
2. Try to remember what you did
3. Struggle to document decisions
4. Documentation becomes outdated
5. Context is lost
```

### Orchestrator Approach
```
1. Plan the work with the Architect
2. Implement with the Implementer (with inline documentation)
3. Test comprehensively with the Tester
4. Review and improve with the Reviewer
5. Synthesize user docs with the Documenter
6. Everything is automatically preserved and searchable
```

## Best Practices

### 1. Clear Task Descriptions
```
âŒ Vague: "Fix the bug"
âœ… Clear: "Fix authentication timeout bug causing users to be logged out after 5 minutes"
```

### 2. Leverage Task History
```
"Continue the refactoring we started in task 12345"
"Apply the same security patterns we used in the auth module"
```

### 3. Trust Specialist Roles
Each specialist is optimized for their domain. Let them:
- Make technology recommendations
- Suggest best practices
- Identify potential issues

### 4. Review Generated Artifacts
While specialists produce high-quality outputs, always:
- Review for your specific requirements
- Customize for your team's conventions
- Validate against your constraints

### 5. Build on Previous Work
The orchestrator's memory is its superpower:
- Reference past decisions
- Reuse successful patterns
- Learn from previous issues

### 6. Ask Questions of the Past
Use the query system to understand your codebase:
- "What security measures did we implement?"
- "How did we handle error cases in similar features?"
- "What performance optimizations have we tried?"

## Real-World Benefits

### For Individual Developers
- Never lose context when switching projects
- Understand your own code months later
- Build on past decisions intelligently
- Avoid repeating mistakes

### For Teams  
- Eliminate knowledge silos
- Onboard new members with rich project history
- Maintain consistency across the codebase
- Enable true asynchronous collaboration

### For AI-Assisted Development
- Provide rich context to AI assistants
- Build on previous work intelligently
- Create self-documenting codebases
- Enable AI to understand not just what, but why

## Next Steps

Now that you understand the core concepts:

1. **[Create your first task](../basic/single-task.md)**
2. **[Try the Quick Start Guide](../../quick-start/README.md)**
3. **[Learn about workspace detection](../intermediate/workspace-detection.md)**
4. **[Master the query system](../advanced/querying-tasks.md)**
5. **[Understand the documentation philosophy](../../PHILOSOPHY.md)**